{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0d600b6-5377-4c5c-a011-9b2e61a4018c",
   "metadata": {},
   "source": [
    "# Galaxy Classification, Anomaly Detection, Autoencoder & VAE (Keras)\n",
    "This notebook uses the Galaxy10 DECaLS dataset (astronomical galaxy images) for:\n",
    "\n",
    "1. Data loading & splitting, defining an anomaly class  \n",
    "2. CNN classifier + ROC curves & confusion matrices  \n",
    "3. Convolutional autoencoder for anomaly detection  \n",
    "4. Variational autoencoder (VAE) + galaxy generation\n",
    "\n",
    "Dataset: Galaxy10 DECaLS (HDF5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0405a22e-6256-41bf-b1a4-8ab6b8dec0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, ops, Model, random\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b69305b-ce16-4539-8bf9-fb7c4e4ebeb1",
   "metadata": {},
   "source": [
    "## 1. Download the dataset, inspect classes, create anomaly split\n",
    "\n",
    "Steps:\n",
    "- Download `Galaxy10_DECals_64.h5` \n",
    "- Load images and labels with `h5py`\n",
    "- Inspect shape and class distribution\n",
    "- Remove class 4 and store it as the anomaly dataset\n",
    "- Split remaining (standard) data into train (50%), val (25%), test (25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b894ed2-1915-47eb-b716-5246f25e926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Galaxy10 DECaLS (HDF5) \n",
    "! rm ./Galaxy10_DECals_64.h5\n",
    "! wget https://cernbox.cern.ch/remote.php/dav/public-files/RyWK8CBk2yqKR0b/Galaxy10_DECals_64.h5\n",
    "data_path = \"./Galaxy10_DECals_64.h5\"\n",
    "\n",
    "print(\"Downloaded to:\", data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aae2712-8c0f-4fd3-8dc8-7bfa1a024d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels using h5py\n",
    "with h5py.File(data_path, \"r\") as f:\n",
    "    images = np.array(f[\"images\"])   # shape (17736, 256, 256, 3)\n",
    "    labels = np.array(f[\"ans\"])      # shape (17736,)\n",
    "\n",
    "#  normalize pixels in [0,1]\n",
    "images = images/255\n",
    "\n",
    "print(\"Images shape:\", images.shape)\n",
    "print(\"Labels shape:\", labels.shape, \"dtype:\", labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84923652-4b90-45e2-bbd7-ce076c3fc0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class names from the Galaxy10 DECaLS documentation\n",
    "class_names = {\n",
    "    0: \"Disturbed Galaxies\",\n",
    "    1: \"Merging Galaxies\",\n",
    "    2: \"Round Smooth Galaxies\",\n",
    "    3: \"In-between Round Smooth Galaxies\",\n",
    "    4: \"Cigar Shaped Smooth Galaxies\",  # will be 'anomaly'\n",
    "    5: \"Barred Spiral Galaxies\",\n",
    "    6: \"Unbarred Tight Spiral Galaxies\",\n",
    "    7: \"Unbarred Loose Spiral Galaxies\",\n",
    "    8: \"Edge-on Galaxies without Bulge\",\n",
    "    9: \"Edge-on Galaxies with Bulge\"\n",
    "}\n",
    "\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "print(\"Class distribution:\")\n",
    "for u, c in zip(unique, counts):\n",
    "    print(f\"Class {u} ({class_names[u]}): {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0b298b-693f-4c23-a289-d4af98b077e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a grid of sample images from different classes\n",
    "def show_examples(images, labels, class_names, n_rows=2, n_cols=5):\n",
    "    plt.figure(figsize=(3*n_cols, 3*n_rows))\n",
    "    indices = np.random.choice(len(images), size=n_rows*n_cols, replace=False)\n",
    "    for i, idx in enumerate(indices):\n",
    "        plt.subplot(n_rows, n_cols, i+1)\n",
    "        plt.imshow(images[idx])\n",
    "        plt.title(f\"Class {labels[idx]}:\\n{class_names[int(labels[idx])]}\", fontsize=8)\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_examples(images, labels, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7314b848-78d6-4023-97c6-dd194491877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create anomaly dataset: all class 0 images\n",
    "ANOMALY_CLASS = 0\n",
    "\n",
    "anomaly_mask = (labels == ANOMALY_CLASS)\n",
    "standard_mask = ~anomaly_mask\n",
    "\n",
    "anom_images = images[anomaly_mask]\n",
    "anom_labels = labels[anomaly_mask]  # all 0, but we keep them for bookkeeping\n",
    "\n",
    "std_images = images[standard_mask]\n",
    "std_labels_original = labels[standard_mask]\n",
    "\n",
    "print(\"Standard images:\", std_images.shape)\n",
    "print(\"Anomaly images:\", anom_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12ea4c4-f9a4-4d63-9f5f-ac6aa87c9a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training, remap standard labels from {0,1,2,3,5,6,7,8,9} -> {0,...,8}\n",
    "unique_std_classes = sorted(np.unique(std_labels_original))\n",
    "print(\"Standard classes (original indices):\", unique_std_classes)\n",
    "\n",
    "# Create mapping dict\n",
    "label_map = {original: new for new, original in enumerate(unique_std_classes)}\n",
    "inv_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "print(\"Label map (original -> new):\", label_map)\n",
    "\n",
    "std_labels = np.vectorize(label_map.get)(std_labels_original)\n",
    "print(\"Remapped standard labels min/max:\", std_labels.min(), std_labels.max())\n",
    "n_classes = len(unique_std_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b0e42f-90ab-4326-ace5-36658b3ccf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split standard data: 50% train, 25% val, 25% test\n",
    "\n",
    "# First split: train (50%) and temp (50%)\n",
    "X_train_std, X_temp_std, y_train_std, y_temp_std = train_test_split(\n",
    "    std_images,\n",
    "    std_labels,\n",
    "    test_size=0.5,\n",
    "    stratify=std_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Second split: temp into val (25%) and test (25%) of full standard data\n",
    "X_val_std, X_test_std, y_val_std, y_test_std = train_test_split(\n",
    "    X_temp_std,\n",
    "    y_temp_std,\n",
    "    test_size=0.5,\n",
    "    stratify=y_temp_std,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train standard:\", X_train_std.shape, y_train_std.shape)\n",
    "print(\"Val standard:  \", X_val_std.shape, y_val_std.shape)\n",
    "print(\"Test standard: \", X_test_std.shape, y_test_std.shape)\n",
    "del std_images, std_labels, X_temp_std, y_temp_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cf6fb6-fcff-4e70-86ae-8e2de5d029d9",
   "metadata": {},
   "source": [
    "## 2. CNN classifier + ROC curves + confusion matrices\n",
    "\n",
    "Steps:\n",
    "- Build a CNN classifier on the **standard** dataset (9 classes)\n",
    "- Train on train set, validate on val set\n",
    "- Plot training history (loss & accuracy)\n",
    "- Compute ROC curves (one-vs-rest) on the standard test set\n",
    "- Compute confusion matrix for standard test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f681f715-a45c-40a0-a773-b1e671b8097d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12283832-c48c-47a5-9e64-8644ad0a4073",
   "metadata": {},
   "source": [
    "## 3. Convolutional Autoencoder for anomaly detection\n",
    "\n",
    "Steps:\n",
    "- Train a convolutional autoencoder on **standard** train set only\n",
    "- Plot training history\n",
    "- Compute reconstruction loss (MSE) per image for:\n",
    "  - Standard test set\n",
    "  - Anomaly dataset (class 4)\n",
    "- Plot histograms of reconstruction losses\n",
    "- Use reconstruction loss as anomaly score and build ROC curve & confusion matrix (adapt provided code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4794c063-c5a9-41d7-8955-53ccf03b14e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65e65481-9247-4f8a-b5c8-c1394656d9f3",
   "metadata": {},
   "source": [
    "## 4. Variational Autoencoder (VAE) on standard data\n",
    "\n",
    "Steps:\n",
    "- Build a VAE with convolutional encoder/decoder (trained on standard train set)\n",
    "- Plot training history\n",
    "- Generate new galaxy images from the VAE\n",
    "- Visualize some generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b06da04-33b4-4e0b-bd08-94f9aafaf3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
