{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54052ed4-a602-465c-b653-569daffc964f",
   "metadata": {},
   "source": [
    "# Muliclass classifier on IRIS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2be0512-5492-4dd1-a17b-dbe84a7df143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43ab53c-1a4f-483a-81ee-478bbaa46913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features\n",
    "y = iris.target  # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfbd32a-edae-43cd-aae5-3af09b849bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the labels: use (1,0,0), (0,1,0), (0,0,1)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf108d1f-7921-4d2b-b4e6-a8176fa11315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training (60%), test (20%), and validation (20%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cacf897-535b-4f0a-b298-69dec2da3f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shapes of the datasets\n",
    "print(f\"Training set shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
    "print(f\"Validation set shape: X_val={X_val.shape}, y_val={y_val.shape}\")\n",
    "print(f\"Test set shape: X_test={X_test.shape}, y_test={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e071ba78-a79d-42e7-87dd-da70ae3f02d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove not needed datasets to reduce memory consumption\n",
    "del X_temp, y_temp, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce83550-9277-412b-8229-0b6fd92caac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa509197-0701-4a99-8e51-a2e9bbd45f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add layers\n",
    "model.add(Input(shape=(X_train.shape[1],)))\n",
    "model.add(Dense(16, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))  # Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635eec20-31af-445e-b87c-84fb17149677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb205b30-a067-417b-827c-c9ad554b984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14095682-5176-45f2-89ab-4cd0c4c53dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3118992-16ff-4301-9164-3a26ad8cc93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss vs epochs\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss vs Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b821cb-ae9b-4ef6-93f4-8cda6f8442db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss vs epochs\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy vs Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ccf93-4160-496e-b093-214026db5509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c639b5-6a49-4875-8017-0fdc24ba1284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve for the test dataset (One-vs-Rest)\n",
    "n_classes = y_test.shape[1]\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "y_score = model.predict(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.yscale(\"log\")\n",
    "colors = ['aqua', 'darkorange', 'cornflowerblue']\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'ROC curve (area = {roc_auc[i]:.2f}) for class {i}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)  # Diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.01, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Multi-Class Classification')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af8ab6-da20-4ead-93c1-cbbf9bae0e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for the test dataset\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)  # Convert probabilities to class labels\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "            xticklabels=iris.target_names,\n",
    "            yticklabels=iris.target_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdce1ba-b323-4c75-b0d6-541ed1ef94b3",
   "metadata": {},
   "source": [
    "# Binary classifier on TITANIC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cf13f5-5a9a-4f44-a4cc-986faf6f6d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea219b6d-15f3-4ff0-8f2b-df513ca76ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Titanic dataset \n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "titanic_data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbda984-eeff-4c5d-83a4-1535e85b365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataset\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82b6e92-5c5c-445c-aee5-bb2826df6234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some standard processing \n",
    "# Fill missing values in 'Age' with the median age\n",
    "titanic_data['Age'].fillna(titanic_data['Age'].median(), inplace=True)\n",
    "\n",
    "# Fill missing values in 'Embarked' with the mode (most frequent value)\n",
    "titanic_data['Embarked'].fillna(titanic_data['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Drop rows where 'Fare' is missing (if any)\n",
    "titanic_data.dropna(subset=['Fare'], inplace=True)\n",
    "\n",
    "# Drop unnecessary columns (PassengerId, Name, Ticket, Cabin)\n",
    "titanic_data.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'], inplace=True)\n",
    "\n",
    "# Convert categorical features 'Sex' and 'Embarked' to numeric using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "titanic_data['Sex'] = label_encoder.fit_transform(titanic_data['Sex'])\n",
    "titanic_data['Embarked'] = label_encoder.fit_transform(titanic_data['Embarked'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be811e17-4bad-4ebb-80d0-94105affad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = titanic_data.drop(columns=['Survived'])\n",
    "y = titanic_data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb04b2-f7c0-4a28-9f88-ff051d1fdeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb6b262-415e-46cc-ac25-97a60d8358a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training (60%), test (20%), and validation (20%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2c70b8-8596-4238-9b4c-95c913ae1da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove not needed datasets to reduce memory consumption\n",
    "del X_temp, y_temp, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07891bb1-f87b-4f8e-b890-7c26675a7a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shapes of the datasets\n",
    "print(f\"Training set shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
    "print(f\"Validation set shape: X_val={X_val.shape}, y_val={y_val.shape}\")\n",
    "print(f\"Test set shape: X_test={X_test.shape}, y_test={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bceba35-c0c5-42e7-9224-978ad2880d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf4394-5e18-4928-a1ee-bd99d95eb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a4462c-b94d-4f08-b8b6-fb855434f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbbda06-0818-49e5-a90e-52d4ff5a3f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad94af-ced1-4a21-b124-82af6969d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f049fd-d249-4dd3-87b9-e9c41e663624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy vs epochs\n",
    "\n",
    "# Plot training & validation loss vs epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1920da-8f8e-48f0-86ba-a0f627963d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c10549-ce74-4cfe-8f8a-e8ffa183c8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC Curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdf8691-48c5-485b-b40e-c7ab78990d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and plot confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31edf1c-610e-407e-b0a2-882233cc1078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
