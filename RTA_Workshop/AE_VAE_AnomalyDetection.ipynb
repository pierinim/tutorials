bplist00—_WebMainResource’	
_WebResourceFrameName_WebResourceData_WebResourceMIMEType_WebResourceTextEncodingName^WebResourceURLPOâA<html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an Anomalous Jet Detector with **Conv 2D** \n",
    "\n",
    "---\n",
    "In this notebook, we train an unsupervised algorithm capable of compressing a jet image into a low-dimension laten space and, from there, reconstruct the input image. The distance between the input and te output is used to identify rare jet configurations. Applying a lower treshold on the loss, one can veto standard QCD jets (quarks and gluons) and select a sample enriched in anomalous jets (W, Z, top, etc). The model uses (De)Conv2D and Dense layers to process the image.\n",
    "\n",
    "This is based on the following papers:\n",
    "- https://arxiv.org/pdf/1808.08992.pdf\n",
    "- https://arxiv.org/pdf/1808.08979.pdf\n",
    "\n",
    "For details on the dataset, see Notebook1 and Notebook3\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of the training and validation samples\n",
    "\n",
    "---\n",
    "In order to import the dataset, we now\n",
    "- clone the dataset repository (to import the data in Colab)\n",
    "- load the h5 files in the data/ repository\n",
    "- extract the data we need: a target and jetImage \n",
    "\n",
    "To type shell commands, we start the command line with !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/pierinim/tutorials.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls tutorials/Data/JetDataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending ../../Data/JetDataset/jetImage_7_100p_30000_40000.h5\n",
      "Appending ../../Data/JetDataset/jetImage_7_100p_60000_70000.h5\n",
      "Appending ../../Data/JetDataset/jetImage_7_100p_50000_60000.h5\n",
      "Appending ../../Data/JetDataset/jetImage_7_100p_10000_20000.h5\n",
      "Appending ../../Data/JetDataset/jetImage_7_100p_0_10000.h5\n",
      "(50000, 5) (50000, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "target = np.array([])\n",
    "jetImage = np.array([])\n",
    "# we cannot load all data on Colab. So we just take a few files\n",
    "datafiles = ['../../Data/JetDataset/jetImage_7_100p_30000_40000.h5',\n",
    "           '../../Data/JetDataset/jetImage_7_100p_60000_70000.h5',\n",
    "            '../../Data/JetDataset/jetImage_7_100p_50000_60000.h5',\n",
    "            '../../Data/JetDataset/jetImage_7_100p_10000_20000.h5',\n",
    "            '../../Data/JetDataset/jetImage_7_100p_0_10000.h5']\n",
    "# if you are running locallt, you can use the full dataset doing\n",
    "# for fileIN in glob.glob(\"tutorials/HiggsSchool/data/*h5\"):\n",
    "for fileIN in datafiles:\n",
    "    print(\"Appending %s\" %fileIN)\n",
    "    f = h5py.File(fileIN)\n",
    "    myjetImage = np.array(f.get(\"jetImage\"))\n",
    "    mytarget = np.array(f.get('jets')[0:,-6:-1])\n",
    "    jetImage = np.concatenate([jetImage, myjetImage], axis=0) if jetImage.size else myjetImage\n",
    "    target = np.concatenate([target, mytarget], axis=0) if target.size else mytarget\n",
    "print(target.shape, jetImage.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In keras, images are representable as $n \\times m \\times k$ tensors, where $n \\times m$ are the pixel dimenions and $k$ is the number of channels (e.g., 1 in a black\\&amp;while image, 3 for an RGB image). In our case, k=1. To comply to this, we add the channel index by reshaping the image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "jetImage = jetImage.reshape((jetImage.shape[0], jetImage.shape[1], jetImage.shape[2], 1))\n",
    "print(jetImage.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now separate the dataset in 4:\n",
    "- a training dataset, consisting of quarks and gluons\n",
    "- three 'anomalous jets' samples: W, Z, and top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19908, 100, 100, 1) (10015, 100, 100, 1) (10037, 100, 100, 1) (10040, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "jetImage_standard = jetImage[np.argmax(target,axis=1)&lt;2]\n",
    "jetImage_W = jetImage[np.argmax(target,axis=1)==2]\n",
    "jetImage_Z = jetImage[np.argmax(target,axis=1)==3]\n",
    "jetImage_t = jetImage[np.argmax(target,axis=1)==4]\n",
    "print(jetImage_standard.shape, jetImage_W.shape, jetImage_Z.shape, jetImage_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this is an unsupervised algorithm, so we don't need the target array anymore.\n",
    "Nevertheless, we keep a part of it around, since it might be useful to test the response \n",
    "of the algorithm to quarks and gluons separetly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_standard = target[np.argmax(target,axis=1)&lt;2]\n",
    "del target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now shuffle the standard-jet data and its labels, splitting them into a training, a validation+test dataset with 2:1:1 ratio. \n",
    "\n",
    "Then we separate the validation+test in two halves (training and validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9954, 100, 100, 1) (9954, 100, 100, 1) (9954, 5) (9954, 5)\n",
      "(9954, 100, 100, 1) (4977, 100, 100, 1) (4977, 100, 100, 1) (9954, 5) (9954, 5) (4977, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, label_train, label_val = t= train_test_split(jetImage_standard, label_standard, test_size=0.5)\n",
    "print(X_train.shape, X_val.shape, label_train.shape, label_val.shape)\n",
    "len_val = X_val.shape[0]\n",
    "X_test = X_val[int(len_val/2.):,:,:,:]\n",
    "label_test = label_val[int(len_val/2.):,:]\n",
    "X_val = X_val[:int(len_val/2.),:,:,:]\n",
    "label_test = label_val[:int(len_val/2.),:]\n",
    "print(X_train.shape, X_val.shape, X_test.shape, label_train.shape, label_val.shape, label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some cleanup to save memory\n",
    "del jetImage, jetImage_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the ConVAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras imports\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Conv2D, Flatten, Activation, Deconv2D, Lambda\n",
    "from keras.layers import MaxPooling2D, BatchNormalization, Activation, Reshape, UpSampling2D\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.losses import mse\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = X_train.shape[1]\n",
    "img_cols = X_train.shape[2]\n",
    "image_shape = (img_rows, img_cols, 1)\n",
    "latent_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENCODER ===\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 100, 100, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 100, 100, 10) 260         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 100, 100, 10) 40          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 100, 100, 10) 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 20, 20, 10)   0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 20, 20, 15)   2415        max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 20, 20, 15)   60          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 20, 20, 15)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 4, 4, 15)     0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 4, 4, 20)     4820        max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, 4, 20)     80          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 4, 4, 20)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 1, 1, 20)     0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 20)           0           max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 10)           210         flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 5)            55          dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 5)            55          dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 5)            0           dense_12[0][0]                   \n",
      "                                                                 dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,995\n",
      "Trainable params: 7,905\n",
      "Non-trainable params: 90\n",
      "__________________________________________________________________________________________________\n",
      "=== DECODER ===\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 20)                120       \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 1, 1, 20)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 4, 4, 20)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 4, 4, 20)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 4, 4, 15)          4815      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 4, 4, 15)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 20, 20, 15)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 20, 20, 15)        60        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 20, 20, 10)        2410      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 20, 20, 10)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 100, 100, 10)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 100, 100, 10)      40        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 100, 100, 1)       161       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 100, 100, 1)       0         \n",
      "=================================================================\n",
      "Total params: 7,686\n",
      "Trainable params: 7,596\n",
      "Non-trainable params: 90\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#---------------------------\n",
    "# Reparametrization trick\n",
    "#---------------------------\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean = 0 and std = 1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "#---------\n",
    "# Enncoder\n",
    "#---------\n",
    "inputImage = Input(shape=(image_shape))\n",
    "#\n",
    "x = Conv2D(10, kernel_size=(5, 5), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(inputImage)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D( pool_size = (5, 5))(x)\n",
    "#\n",
    "x = Conv2D(15, kernel_size=(4, 4), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D( pool_size = (5, 5))(x)\n",
    "#\n",
    "x = Conv2D(20, kernel_size=(4, 4), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D( pool_size = (4, 4))(x)\n",
    "#\n",
    "x = Flatten()(x)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(x)\n",
    "z_log_var = Dense(latent_dim)(x)\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "encoder = Model(inputImage, [z_mean, z_log_var, z], name='encoder')\n",
    "print(\"=== ENCODER ===\")\n",
    "encoder.summary()\n",
    "\n",
    "#---------\n",
    "# Decoder\n",
    "#---------\n",
    "latent_input = Input(shape=(latent_dim,))\n",
    "x = Dense(20, activation='relu')(latent_input)\n",
    "x = Reshape((1, 1, 20))(x)\n",
    "#\n",
    "x = UpSampling2D((4, 4))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Deconv2D(15, kernel_size=(4,4), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(x)\n",
    "x = Activation('relu')(x)\n",
    "#\n",
    "x = UpSampling2D((5, 5))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Deconv2D(10, kernel_size=(4,4), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(x)\n",
    "x = Activation('relu')(x)\n",
    "#\n",
    "x = UpSampling2D((5, 5))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Deconv2D(1, kernel_size=(4,4), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(x)\n",
    "dec = Activation('relu')(x)\n",
    "decoder = Model(latent_input, dec, name = 'decoder')\n",
    "print(\"=== DECODER ===\")\n",
    "decoder.summary()\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputImage)[2])\n",
    "vae = Model(inputImage, outputs, name='vae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 100, 100, 1)       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 5), (None, 5), (N 7995      \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 100, 100, 1)       7686      \n",
      "=================================================================\n",
      "Total params: 15,681\n",
      "Trainable params: 15,501\n",
      "Non-trainable params: 180\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    return mse(tf.reshape(y_true, [-1,100*100]), tf.reshape(y_pred, [-1, 100*100]))\n",
    "\n",
    "def vae_loss(y_true, y_pred):\n",
    "    reconstruction_loss = mean_squared_error(y_true, y_pred)\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    return K.mean(reconstruction_loss - 0.5 * kl_loss)\n",
    "\n",
    "vae.compile(optimizer='adam', loss=vae_loss)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train the model. Notice the difference with respect to the supervised case\n",
    "- the input to the training is (X,X) and nor (X, y). Similarly for the validation dataset\n",
    "- the model has no dropout. It is difficult for an unsupervised model to overtran, so there is not really a need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 4977 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 112.1557 - val_loss: 124.0989\n",
      "Epoch 2/100\n",
      " - 8s - loss: 61.4006 - val_loss: 74.2982\n",
      "Epoch 3/100\n",
      " - 7s - loss: 56.1493 - val_loss: 67.5145\n",
      "Epoch 4/100\n",
      " - 7s - loss: 54.7078 - val_loss: 62.2939\n",
      "Epoch 5/100\n",
      " - 7s - loss: 53.8893 - val_loss: 56.9474\n",
      "Epoch 6/100\n",
      " - 7s - loss: 52.5950 - val_loss: 53.8851\n",
      "Epoch 7/100\n",
      " - 7s - loss: 51.0353 - val_loss: 51.2629\n",
      "Epoch 8/100\n",
      " - 7s - loss: 49.9329 - val_loss: 49.9086\n",
      "Epoch 9/100\n",
      " - 7s - loss: 49.1766 - val_loss: 49.4003\n",
      "Epoch 10/100\n",
      " - 7s - loss: 48.8555 - val_loss: 48.5525\n",
      "Epoch 11/100\n",
      " - 7s - loss: 48.6413 - val_loss: 48.3077\n",
      "Epoch 12/100\n",
      " - 7s - loss: 48.4488 - val_loss: 48.1062\n",
      "Epoch 13/100\n",
      " - 7s - loss: 48.2861 - val_loss: 48.0478\n",
      "Epoch 14/100\n",
      " - 7s - loss: 48.1646 - val_loss: 47.9986\n",
      "Epoch 15/100\n",
      " - 7s - loss: 48.0523 - val_loss: 47.8143\n",
      "Epoch 16/100\n",
      " - 7s - loss: 47.6999 - val_loss: 47.4609\n",
      "Epoch 17/100\n",
      " - 7s - loss: 47.1448 - val_loss: 46.4270\n",
      "Epoch 18/100\n",
      " - 7s - loss: 45.6723 - val_loss: 45.1525\n",
      "Epoch 19/100\n",
      " - 7s - loss: 44.3755 - val_loss: 43.6853\n",
      "Epoch 20/100\n",
      " - 7s - loss: 43.5154 - val_loss: 43.0339\n",
      "Epoch 21/100\n",
      " - 7s - loss: 42.8186 - val_loss: 42.3366\n",
      "Epoch 22/100\n",
      " - 7s - loss: 42.6388 - val_loss: 42.3880\n",
      "Epoch 23/100\n",
      " - 7s - loss: 42.4290 - val_loss: 41.5943\n",
      "Epoch 24/100\n",
      " - 7s - loss: 42.2810 - val_loss: 41.6060\n",
      "Epoch 25/100\n",
      " - 7s - loss: 42.0049 - val_loss: 42.0458\n",
      "Epoch 26/100\n",
      " - 7s - loss: 41.8017 - val_loss: 40.9177\n",
      "Epoch 27/100\n",
      " - 7s - loss: 41.0244 - val_loss: 40.7917\n",
      "Epoch 28/100\n",
      " - 7s - loss: 40.2701 - val_loss: 42.0703\n",
      "Epoch 29/100\n",
      " - 7s - loss: 39.6477 - val_loss: 39.4228\n",
      "Epoch 30/100\n",
      " - 7s - loss: 39.3816 - val_loss: 38.4494\n",
      "Epoch 31/100\n",
      " - 7s - loss: 38.7847 - val_loss: 38.3998\n",
      "Epoch 32/100\n",
      " - 7s - loss: 38.6661 - val_loss: 38.8851\n",
      "Epoch 33/100\n",
      " - 7s - loss: 38.2457 - val_loss: 37.7086\n",
      "Epoch 34/100\n",
      " - 7s - loss: 38.1971 - val_loss: 37.1421\n",
      "Epoch 35/100\n",
      " - 7s - loss: 37.9117 - val_loss: 45.6912\n",
      "Epoch 36/100\n",
      " - 7s - loss: 38.0470 - val_loss: 38.1509\n",
      "Epoch 37/100\n",
      " - 7s - loss: 37.8434 - val_loss: 36.1034\n",
      "Epoch 38/100\n",
      " - 7s - loss: 37.3469 - val_loss: 36.1833\n",
      "Epoch 39/100\n",
      " - 7s - loss: 36.7762 - val_loss: 36.2188\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: reducing learning rate to 0.00010000000474974513.\n",
      " - 7s - loss: 37.1026 - val_loss: 39.5252\n",
      "Epoch 41/100\n",
      " - 7s - loss: 35.9876 - val_loss: 35.3106\n",
      "Epoch 42/100\n",
      " - 7s - loss: 35.5331 - val_loss: 34.8816\n",
      "Epoch 43/100\n",
      " - 7s - loss: 35.3623 - val_loss: 34.7987\n",
      "Epoch 44/100\n",
      " - 7s - loss: 35.3861 - val_loss: 34.7823\n",
      "Epoch 45/100\n",
      " - 7s - loss: 35.2666 - val_loss: 34.5458\n",
      "Epoch 46/100\n",
      " - 7s - loss: 35.0770 - val_loss: 34.4400\n",
      "Epoch 47/100\n",
      " - 7s - loss: 35.0418 - val_loss: 34.1784\n",
      "Epoch 48/100\n",
      " - 7s - loss: 34.8925 - val_loss: 34.2266\n",
      "Epoch 49/100\n",
      " - 7s - loss: 34.9545 - val_loss: 34.0602\n",
      "Epoch 50/100\n",
      " - 7s - loss: 34.8554 - val_loss: 33.9446\n",
      "Epoch 51/100\n",
      " - 7s - loss: 34.4591 - val_loss: 33.7118\n",
      "Epoch 52/100\n",
      " - 7s - loss: 34.6218 - val_loss: 33.6171\n",
      "Epoch 53/100\n",
      " - 7s - loss: 34.3051 - val_loss: 33.5556\n",
      "Epoch 54/100\n",
      " - 7s - loss: 34.3725 - val_loss: 33.5776\n",
      "Epoch 55/100\n",
      " - 7s - loss: 34.4340 - val_loss: 33.6258\n",
      "Epoch 56/100\n",
      " - 7s - loss: 34.2385 - val_loss: 33.1956\n",
      "Epoch 57/100\n",
      " - 7s - loss: 34.1306 - val_loss: 33.2332\n",
      "Epoch 58/100\n",
      " - 7s - loss: 34.0502 - val_loss: 33.0164\n",
      "Epoch 59/100\n",
      " - 7s - loss: 33.8104 - val_loss: 33.0321\n",
      "Epoch 60/100\n",
      " - 7s - loss: 33.8215 - val_loss: 32.9117\n",
      "Epoch 61/100\n",
      " - 7s - loss: 33.4157 - val_loss: 32.7365\n",
      "Epoch 62/100\n",
      " - 7s - loss: 33.5817 - val_loss: 32.8355\n",
      "Epoch 63/100\n",
      " - 7s - loss: 33.3919 - val_loss: 32.4007\n",
      "Epoch 64/100\n",
      " - 7s - loss: 33.2751 - val_loss: 32.4616\n",
      "Epoch 65/100\n",
      " - 7s - loss: 33.2431 - val_loss: 32.2984\n",
      "Epoch 66/100\n",
      " - 7s - loss: 33.1470 - val_loss: 32.1259\n",
      "Epoch 67/100\n",
      " - 7s - loss: 32.8874 - val_loss: 32.0432\n",
      "Epoch 68/100\n",
      " - 7s - loss: 33.0352 - val_loss: 32.1283\n",
      "Epoch 69/100\n",
      " - 7s - loss: 32.8710 - val_loss: 32.0918\n",
      "Epoch 70/100\n",
      " - 7s - loss: 32.6684 - val_loss: 31.7757\n",
      "Epoch 71/100\n",
      " - 7s - loss: 32.6031 - val_loss: 31.8008\n",
      "Epoch 72/100\n",
      " - 7s - loss: 32.5403 - val_loss: 31.6530\n",
      "Epoch 73/100\n",
      " - 7s - loss: 32.5693 - val_loss: 31.6932\n",
      "Epoch 74/100\n",
      " - 7s - loss: 32.4420 - val_loss: 31.4146\n",
      "Epoch 75/100\n",
      " - 7s - loss: 32.4101 - val_loss: 31.5357\n",
      "Epoch 76/100\n",
      " - 7s - loss: 32.3404 - val_loss: 31.3598\n",
      "Epoch 77/100\n",
      " - 7s - loss: 32.2443 - val_loss: 31.2002\n",
      "Epoch 78/100\n",
      " - 7s - loss: 32.1692 - val_loss: 31.0286\n",
      "Epoch 79/100\n",
      " - 7s - loss: 32.0244 - val_loss: 30.9872\n",
      "Epoch 80/100\n",
      " - 7s - loss: 32.1075 - val_loss: 31.1729\n",
      "Epoch 81/100\n",
      " - 7s - loss: 31.9839 - val_loss: 30.8566\n",
      "Epoch 82/100\n",
      " - 7s - loss: 31.7256 - val_loss: 30.8436\n",
      "Epoch 83/100\n",
      " - 7s - loss: 31.6337 - val_loss: 30.7227\n",
      "Epoch 84/100\n",
      " - 7s - loss: 31.5980 - val_loss: 30.6071\n",
      "Epoch 85/100\n",
      " - 7s - loss: 31.6085 - val_loss: 30.8549\n",
      "Epoch 86/100\n",
      " - 7s - loss: 31.4702 - val_loss: 30.4438\n",
      "Epoch 87/100\n",
      " - 7s - loss: 31.5263 - val_loss: 30.4838\n",
      "Epoch 88/100\n",
      " - 7s - loss: 31.2385 - val_loss: 30.6605\n",
      "Epoch 89/100\n",
      " - 7s - loss: 31.3551 - val_loss: 30.1885\n",
      "Epoch 90/100\n",
      " - 7s - loss: 31.0292 - val_loss: 30.3176\n",
      "Epoch 91/100\n",
      " - 7s - loss: 31.2543 - val_loss: 30.0477\n",
      "Epoch 92/100\n",
      " - 7s - loss: 31.0302 - val_loss: 30.3510\n",
      "Epoch 93/100\n",
      " - 7s - loss: 30.9902 - val_loss: 30.1450\n",
      "Epoch 94/100\n",
      " - 7s - loss: 30.9977 - val_loss: 30.0085\n",
      "Epoch 95/100\n",
      " - 7s - loss: 31.0019 - val_loss: 30.2393\n",
      "Epoch 96/100\n",
      " - 7s - loss: 30.7856 - val_loss: 30.0471\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: reducing learning rate to 1.0000000474974514e-05.\n",
      " - 7s - loss: 30.8657 - val_loss: 30.0992\n",
      "Epoch 98/100\n",
      " - 7s - loss: 30.7455 - val_loss: 29.7586\n",
      "Epoch 99/100\n",
      " - 7s - loss: 30.7554 - val_loss: 29.6961\n",
      "Epoch 100/100\n",
      " - 7s - loss: 30.8258 - val_loss: 29.7712\n"
     ]
    }
   ],
   "source": [
    "# train \n",
    "history = vae.fit(X_train, X_train, epochs=n_epochs, batch_size=batch_size, verbose = 2,\n",
    "                validation_data=(X_val, X_val),\n",
    "                callbacks = [\n",
    "                EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1),\n",
    "                TerminateOnNaN()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training history\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.yscale('log')\n",
    "plt.title('Training History')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save on disk the best model, result of the training, to be then use for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = autoencoder.to_json()\n",
    "with open(\"tutorials/HiggsSchool/models/jetAE_Conv2D.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "autoencoder.save_weights(\"tutorials/HiggsSchool/models/jetAE_Conv2D.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['W', 'Z', 'top']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly = [jetImage_W, jetImage_Z, jetImage_t]\n",
    "predictedQCD = autoencoder.predict(X_test)\n",
    "predicted_anomaly = []\n",
    "for i in range(len(labels)):\n",
    "    predicted_anomaly.append(autoencoder.predict(anomaly[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(image_in, image_out):\n",
    "    mse = (image_out-image_in)*(image_out-image_in)\n",
    "    # sum over channel\n",
    "    mse = np.sum(mse,axis=-1)\n",
    "    # sum over y\n",
    "    mse = np.sum(mse, axis=-1)\n",
    "    # sum over x\n",
    "    mse = np.sum(mse, axis=-1)\n",
    "    return mse    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossQCD = mse(X_test, predictedQCD)\n",
    "loss_anomaly = []\n",
    "for i in range(len(labels)):\n",
    "    loss_anomaly.append(mse(anomaly[i], predicted_anomaly[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossQCD_1 = lossQCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxScore = np.max(lossQCD)\n",
    "# plot QCD\n",
    "plt.figure()\n",
    "plt.hist(lossQCD_1, bins=100, label='QCD', density=True, range=(0, maxScore), \n",
    "         histtype='step', fill=False, linewidth=1.5)\n",
    "plt.semilogy()\n",
    "plt.xlabel(\"AE Loss\")\n",
    "plt.ylabel(\"Probability (a.u.)\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxScore = np.max(lossQCD)\n",
    "# plot QCD\n",
    "plt.figure()\n",
    "plt.hist(lossQCD, bins=100, label='QCD', density=True, range=(0, maxScore), \n",
    "         histtype='step', fill=False, linewidth=1.5)\n",
    "for i in range(len(labels)):\n",
    "    plt.hist(loss_anomaly[i], bins=100, label=labels[i], density=True, range=(0, maxScore),\n",
    "            histtype='step', fill=False, linewidth=1.5)\n",
    "plt.semilogy()\n",
    "plt.xlabel(\"AE Loss\")\n",
    "plt.ylabel(\"Probability (a.u.)\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "plt.figure()\n",
    "targetQCD = np.zeros(lossQCD.shape[0])\n",
    "for i, label in enumerate(labels):\n",
    "        print(loss_anomaly[i].shape, targetQCD.shape)\n",
    "        trueVal = np.concatenate((np.ones(loss_anomaly[i].shape[0]),targetQCD))\n",
    "        predVal = np.concatenate((loss_anomaly[i],lossQCD))\n",
    "        print(trueVal.shape, predVal.shape)\n",
    "        fpr, tpr, threshold = roc_curve(trueVal,predVal)\n",
    "        auc1= auc(fpr, tpr)\n",
    "        plt.plot(tpr,fpr,label='%s Anomaly Detection, auc = %.1f%%'%(label,auc1*100.))\n",
    "plt.semilogy()\n",
    "plt.xlabel(\"sig. efficiency\")\n",
    "plt.ylabel(\"bkg. mistag rate\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
</pre></body></html>Ztext/plainUUTF-8_çhttps://raw.githubusercontent.com/pierinim/tutorials/b171e91acb74cdc58966e0202594b881ea7b62f7/HiggsSchool/Lecture4/Notebook7_VAE_Conv2D.ipynb    ( ? Q g Ö î ïâ⁄âÂâÎ                           ä{