{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an Anomalous Jet Detector with **Conv 2D** \n",
    "\n",
    "---\n",
    "In this notebook, we train an unsupervised algorithm capable of compressing a jet image into a low-dimension laten space and, from there, reconstruct the input image. The distance between the input and te output is used to identify rare jet configurations. Applying a lower treshold on the loss, one can veto standard QCD jets (quarks and gluons) and select a sample enriched in anomalous jets (W, Z, top, etc). The model uses (De)Conv2D and Dense layers to process the image.\n",
    "\n",
    "This is based on the following papers:\n",
    "- https://arxiv.org/pdf/1808.08992.pdf\n",
    "- https://arxiv.org/pdf/1808.08979.pdf\n",
    "\n",
    "For details on the dataset, see Notebook1 and Notebook3\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of the training and validation samples\n",
    "\n",
    "---\n",
    "In order to import the dataset, we now\n",
    "- clone the dataset repository (to import the data in Colab)\n",
    "- load the h5 files in the data/ repository\n",
    "- extract the data we need: a target and jetImage \n",
    "\n",
    "To type shell commands, we start the command line with !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/pierinim/tutorials.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls tutorials/Data/JetDataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.array([])\n",
    "jetImage = np.array([])\n",
    "# we cannot load all data on Colab. So we just take a few files\n",
    "datafiles = ['tutorials/Data/JetDataset/jetImage_7_100p_30000_40000.h5',\n",
    "           'tutorials/Data/JetDataset/jetImage_7_100p_60000_70000.h5',\n",
    "            'tutorials/Data/JetDataset/jetImage_7_100p_50000_60000.h5',\n",
    "            'tutorials/Data/JetDataset/jetImage_7_100p_10000_20000.h5',\n",
    "            'tutorials/Data/JetDataset/jetImage_7_100p_0_10000.h5']\n",
    "# if you are running locallt, you can use the full dataset doing\n",
    "# for fileIN in glob.glob(\"tutorials/HiggsSchool/data/*h5\"):\n",
    "for fileIN in datafiles:\n",
    "    print(\"Appending %s\" %fileIN)\n",
    "    f = h5py.File(fileIN)\n",
    "    myjetImage = np.array(f.get(\"jetImage\"))\n",
    "    mytarget = np.array(f.get('jets')[0:,-6:-1])\n",
    "    jetImage = np.concatenate([jetImage, myjetImage], axis=0) if jetImage.size else myjetImage\n",
    "    target = np.concatenate([target, mytarget], axis=0) if target.size else mytarget\n",
    "print(target.shape, jetImage.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In keras, images are representable as $n \\times m \\times k$ tensors, where $n \\times m$ are the pixel dimenions and $k$ is the number of channels (e.g., 1 in a black\\&while image, 3 for an RGB image). In our case, k=1. To comply to this, we add the channel index by reshaping the image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetImage = jetImage.reshape((jetImage.shape[0], jetImage.shape[1], jetImage.shape[2], 1))\n",
    "print(jetImage.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now separate the dataset in 4:\n",
    "- a training dataset, consisting of quarks and gluons\n",
    "- three 'anomalous jets' samples: W, Z, and top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetImage_standard = jetImage[np.argmax(target,axis=1)<2]\n",
    "jetImage_W = jetImage[np.argmax(target,axis=1)==2]\n",
    "jetImage_Z = jetImage[np.argmax(target,axis=1)==3]\n",
    "jetImage_t = jetImage[np.argmax(target,axis=1)==4]\n",
    "print(jetImage_standard.shape, jetImage_W.shape, jetImage_Z.shape, jetImage_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this is an unsupervised algorithm, so we don't need the target array anymore.\n",
    "Nevertheless, we keep a part of it around, since it might be useful to test the response \n",
    "of the algorithm to quarks and gluons separetly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_standard = target[np.argmax(target,axis=1)<2]\n",
    "del target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now shuffle the standard-jet data and its labels, splitting them into a training, a validation+test dataset with 2:1:1 ratio. \n",
    "\n",
    "Then we separate the validation+test in two halves (training and validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, label_train, label_val = t= train_test_split(jetImage_standard, label_standard, test_size=0.5)\n",
    "print(X_train.shape, X_val.shape, label_train.shape, label_val.shape)\n",
    "len_val = X_val.shape[0]\n",
    "X_test = X_val[int(len_val/2.):,:,:,:]\n",
    "label_test = label_val[int(len_val/2.):,:]\n",
    "X_val = X_val[:int(len_val/2.),:,:,:]\n",
    "label_test = label_val[:int(len_val/2.),:]\n",
    "print(X_train.shape, X_val.shape, X_test.shape, label_train.shape, label_val.shape, label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some cleanup to save memory\n",
    "del jetImage, jetImage_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the ConvAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras imports\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Conv2D, Flatten, Activation, Deconv2D\n",
    "from keras.layers import MaxPooling2D, BatchNormalization, Activation, Reshape, UpSampling2D\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = X_train.shape[1]\n",
    "img_cols = X_train.shape[2]\n",
    "image_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------\n",
    "# Enncoder\n",
    "#---------\n",
    "inputImage = Input(shape=(image_shape))\n",
    "#\n",
    "x = Conv2D(10, kernel_size=(5, 5), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(inputImage)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D( pool_size = (5, 5))(x)\n",
    "#\n",
    "x = Conv2D(15, kernel_size=(4, 4), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D( pool_size = (5, 5))(x)\n",
    "#\n",
    "x = Conv2D(20, kernel_size=(4, 4), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D( pool_size = (4, 4))(x)\n",
    "#\n",
    "x = Flatten()(x)\n",
    "enc = Dense(5, activation='relu')(x)\n",
    "\n",
    "#---------\n",
    "# Decoder\n",
    "#---------\n",
    "\n",
    "x = Dense(20, activation='relu')(enc)\n",
    "x = Reshape((1, 1, 20))(x)\n",
    "#\n",
    "x = UpSampling2D((4, 4))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Deconv2D(15, kernel_size=(4,4), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(x)\n",
    "x = Activation('relu')(x)\n",
    "#\n",
    "x = UpSampling2D((5, 5))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Deconv2D(10, kernel_size=(4,4), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(x)\n",
    "x = Activation('relu')(x)\n",
    "#\n",
    "x = UpSampling2D((5, 5))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Deconv2D(1, kernel_size=(4,4), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(x)\n",
    "dec = Activation('relu')(x)\n",
    "#output = Deconv2D(5, kernel_size=(5,5), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(x)\n",
    "####\n",
    "autoencoder = Model(inputs=inputImage, outputs=dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(loss='mse', optimizer='adam')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train the model. Notice the difference with respect to the supervised case\n",
    "- the input to the training is (X,X) and nor (X, y). Similarly for the validation dataset\n",
    "- the model has no dropout. It is difficult for an unsupervised model to overtran, so there is not really a need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train \n",
    "history = autoencoder.fit(X_train, X_train, epochs=n_epochs, batch_size=batch_size, verbose = 2,\n",
    "                validation_data=(X_val, X_val),\n",
    "                callbacks = [\n",
    "                EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1),\n",
    "                TerminateOnNaN()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training history\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.yscale('log')\n",
    "plt.title('Training History')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save on disk the best model, result of the training, to be then use for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = autoencoder.to_json()\n",
    "with open(\"tutorials/HiggsSchool/models/jetAE_Conv2D.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "autoencoder.save_weights(\"tutorials/HiggsSchool/models/jetAE_Conv2D.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['W', 'Z', 'top']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly = [jetImage_W, jetImage_Z, jetImage_t]\n",
    "predictedQCD = autoencoder.predict(X_test)\n",
    "predicted_anomaly = []\n",
    "for i in range(len(labels)):\n",
    "    predicted_anomaly.append(autoencoder.predict(anomaly[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(image_in, image_out):\n",
    "    mse = (image_out-image_in)*(image_out-image_in)\n",
    "    # sum over channel\n",
    "    mse = np.sum(mse,axis=-1)\n",
    "    # sum over y\n",
    "    mse = np.sum(mse, axis=-1)\n",
    "    # sum over x\n",
    "    mse = np.sum(mse, axis=-1)\n",
    "    return mse    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossQCD = mse(X_test, predictedQCD)\n",
    "loss_anomaly = []\n",
    "for i in range(len(labels)):\n",
    "    loss_anomaly.append(mse(anomaly[i], predicted_anomaly[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossQCD_1 = lossQCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxScore = np.max(lossQCD)\n",
    "# plot QCD\n",
    "plt.figure()\n",
    "plt.hist(lossQCD_1, bins=100, label='QCD', density=True, range=(0, maxScore), \n",
    "         histtype='step', fill=False, linewidth=1.5)\n",
    "plt.semilogy()\n",
    "plt.xlabel(\"AE Loss\")\n",
    "plt.ylabel(\"Probability (a.u.)\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxScore = np.max(lossQCD)\n",
    "# plot QCD\n",
    "plt.figure()\n",
    "plt.hist(lossQCD, bins=100, label='QCD', density=True, range=(0, maxScore), \n",
    "         histtype='step', fill=False, linewidth=1.5)\n",
    "for i in range(len(labels)):\n",
    "    plt.hist(loss_anomaly[i], bins=100, label=labels[i], density=True, range=(0, maxScore),\n",
    "            histtype='step', fill=False, linewidth=1.5)\n",
    "plt.semilogy()\n",
    "plt.xlabel(\"AE Loss\")\n",
    "plt.ylabel(\"Probability (a.u.)\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "plt.figure()\n",
    "targetQCD = np.zeros(lossQCD.shape[0])\n",
    "for i, label in enumerate(labels):\n",
    "        print(loss_anomaly[i].shape, targetQCD.shape)\n",
    "        trueVal = np.concatenate((np.ones(loss_anomaly[i].shape[0]),targetQCD))\n",
    "        predVal = np.concatenate((loss_anomaly[i],lossQCD))\n",
    "        print(trueVal.shape, predVal.shape)\n",
    "        fpr, tpr, threshold = roc_curve(trueVal,predVal)\n",
    "        auc1= auc(fpr, tpr)\n",
    "        plt.plot(tpr,fpr,label='%s Anomaly Detection, auc = %.1f%%'%(label,auc1*100.))\n",
    "plt.semilogy()\n",
    "plt.xlabel(\"sig. efficiency\")\n",
    "plt.ylabel(\"bkg. mistag rate\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
